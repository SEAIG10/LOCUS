"""
ì‹¤ì‹œê°„ ë°ëª¨ - GRU ì˜ˆì¸¡ê¸°
ZeroMQë¡œ ì„¼ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì§‘ í›„ GRU ëª¨ë¸ë¡œ ì˜¤ì—¼ë„ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
"""

import sys
import os
from pathlib import Path

# packages/ai ë° ë¦¬í¬ì§€í† ë¦¬ ë£¨íŠ¸ë¥¼ pathì— ì¶”ê°€
PROJECT_ROOT = Path(__file__).resolve().parents[3]
if str(PROJECT_ROOT) not in sys.path:
    sys.path.append(str(PROJECT_ROOT))
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))

import zmq
import time
import numpy as np
import tensorflow as tf
from collections import deque

# ë‚´ë¶€ ëª¨ë“ˆ ì„í¬íŠ¸
from core.context_fusion.attention_context_encoder import create_attention_encoder
from core.model.gru_model import FedPerGRUModel
from realtime.utils import print_prediction_result, ZONES
from packages.config.zmq_endpoints import (
    SENSOR_STREAM,
    FEDERATED_STREAM,
    POLICY_STREAM,
)
from core.context_fusion.time_sync_buffer import TimeSyncBuffer

# ëª¨ë¸ ê²½ë¡œ
GRU_MODEL_PATH = os.path.join(os.path.dirname(__file__), '..', 'models', 'gru', 'gru_model.keras')

# ì»¨í…ìŠ¤íŠ¸ ë²„í¼ ì„¤ì •
CONTEXT_BUFFER_SIZE = 30  # 30 íƒ€ì„ìŠ¤í…

# ROS ApproximateTimeSynchronizer ë°©ì‹ì˜ ë™ê¸°í™” ì„¤ì •
QUEUE_SIZE = 10  # ê° ì„¼ì„œë³„ í í¬ê¸°
SLOP = 3       # í—ˆìš© ì˜¤ì°¨ (ì´ˆ)


class GRUPredictor:
    """
    GRU Predictor
    ZeroMQë¡œ ì„¼ì„œ ë°ì´í„°ë¥¼ ìˆ˜ì‹ í•˜ì—¬ AttentionContextEncoderë¥¼ ê±°ì¹œ í›„, GRU ëª¨ë¸ë¡œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    ì˜ˆì¸¡ ê²°ê³¼ëŠ” FR4(Federated Learning)ì™€ FR5(Policy Engine)ë¡œ ZeroMQë¥¼ í†µí•´ ì†¡ì‹ ë©ë‹ˆë‹¤.
    """

    def __init__(self):
        print("=" * 60)
        print("GRU Predictor Initializing...")
        print("=" * 60)

        # ZeroMQ Subscriber (ì„¼ì„œ ë²„ìŠ¤ í˜¸ìŠ¤íŠ¸: SUBê°€ bind, ì„¼ì„œë“¤ì€ connect)
        self.zmq_context = zmq.Context.instance()
        self.zmq_socket = self.zmq_context.socket(zmq.SUB)
        self.zmq_socket.bind(SENSOR_STREAM)
        self.zmq_socket.setsockopt_string(zmq.SUBSCRIBE, "")
        print(f"[GRU] ZeroMQ SUB bound to {SENSOR_STREAM}")
        print("[GRU] Subscribed to all sensor messages")

        # ZeroMQ Publishers (FR4, FR5)
        self.zmq_pub_federated = self.zmq_context.socket(zmq.PUB)
        self.zmq_pub_federated.bind(FEDERATED_STREAM)
        print(f"[GRU] ZeroMQ PUB bound to {FEDERATED_STREAM} for FR4")

        self.zmq_pub_policy = self.zmq_context.socket(zmq.PUB)
        self.zmq_pub_policy.bind(POLICY_STREAM)
        print(f"[GRU] ZeroMQ PUB bound to {POLICY_STREAM} for FR5")

        # ëª¨ë¸ ë¡œë“œ
        print("\n[GRU] Loading models...")
        print("  1. AttentionContextEncoder...")
        self.attention_encoder = create_attention_encoder(
            visual_dim=14,
            audio_dim=17,
            pose_dim=51,
            spatial_dim=4,   # balcony, bedroom, kitchen, living_room
            time_dim=10,
            context_dim=160
        )
        print("     AttentionContextEncoder loaded!")

        print(f"  2. GRU Model from {GRU_MODEL_PATH}...")
        self.gru_model = FedPerGRUModel(num_zones=4, context_dim=160)
        self.gru_model.load(GRU_MODEL_PATH)
        print("     GRU Model loaded!")

        # TimeSyncBuffer: ì‹¤ì œ ì„¼ì„œ íƒ€ì…ì— ë§ê²Œ
        self.time_sync = TimeSyncBuffer(
            required_sensors=['visual', 'audio', 'pose', 'spatial', 'time'],
            queue_size=QUEUE_SIZE,
            slop=SLOP,
            on_sync=self.process_context,
        )

        # 30íƒ€ì„ìŠ¤í… ì»¨í…ìŠ¤íŠ¸ ë²„í¼
        self.context_buffer = deque(maxlen=CONTEXT_BUFFER_SIZE)

        # í†µê³„
        self.timestep_count = 0
        self.prediction_count = 0

        print("\nGRU Predictor ready!\n")

    # ---------------------------------------------------------------------- ZMQ
    def receive_messages(self):
        """
        ZeroMQ ë©”ì‹œì§€ë¥¼ TimeSyncBufferë¡œ ì „ë‹¬.
        """
        try:
            if self.zmq_socket.poll(timeout=100):  # 100ms í´ë§
                message = self.zmq_socket.recv_pyobj()

                sensor_type = message.get('type')
                timestamp = message.get('timestamp')
                data = message.get('data')

                if sensor_type is None or timestamp is None or data is None:
                    return

                # ë””ë²„ê·¸ ë¡œê·¸
                print(f"[GRU] recv sensor={sensor_type} ts={timestamp}")

                # íƒ€ì„ì‹±í¬ ë²„í¼ì— push
                self.time_sync.push(sensor_type, timestamp, data)

        except Exception as e:
            print(f"Error in receive_messages: {e}")

    # ----------------------------------------------------------------- CONTEXT
    def process_context(self, sensor_data, timestamp_bucket):
        """
        ë™ê¸°í™”ëœ ì„¼ì„œ ë°ì´í„°(visual, audio, pose, spatial, time)ë¡œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±.
        AttentionContextEncoder â†’ 160ì°¨ì› ë²¡í„° â†’ ë²„í¼ì— ì ì¬.
        """
        try:
            visual_vec = sensor_data['visual']
            audio_vec = sensor_data['audio']
            pose_vec = sensor_data['pose']
            spatial_vec = sensor_data['spatial']
            time_vec = sensor_data['time']

            context_dict = {
                'visual': tf.constant([visual_vec], dtype=tf.float32),
                'audio': tf.constant([audio_vec], dtype=tf.float32),
                'pose': tf.constant([pose_vec], dtype=tf.float32),
                'spatial': tf.constant([spatial_vec], dtype=tf.float32),
                'time': tf.constant([time_vec], dtype=tf.float32),
            }

            # (1, 160) â†’ [0]ìœ¼ë¡œ êº¼ë‚´ì„œ (160,) ë²¡í„°
            context_160 = self.attention_encoder(context_dict, training=False)[0].numpy()

            self.context_buffer.append(context_160)
            self.timestep_count += 1

            print(
                f"[{self.timestep_count:04d}] "
                f"Synced timestep @ {timestamp_bucket:.2f}s â†’ "
                f"Buffer: {len(self.context_buffer)}/{CONTEXT_BUFFER_SIZE}"
            )

            if len(self.context_buffer) == CONTEXT_BUFFER_SIZE:
                self.predict()

        except Exception as e:
            print(f"Error in process_context: {e}")
            import traceback
            traceback.print_exc()

    # ---------------------------------------------------------------- PREDICT
    def predict(self):
        """
        GRU ëª¨ë¸ë¡œ ì˜ˆì¸¡ ìˆ˜í–‰ í›„, ê²°ê³¼ë¥¼ ì¶œë ¥ ë° FR4/FR5ë¡œ ì†¡ì‹ .
        """
        try:
            print("\n" + "=" * 60)
            print(f"Running GRU Prediction #{self.prediction_count + 1}...")
            print("=" * 60)

            X = np.array(self.context_buffer).reshape(1, CONTEXT_BUFFER_SIZE, 160)

            prediction = self.gru_model.predict(X)[0]

            print_prediction_result(prediction, ZONES)

            self.publish_prediction(prediction)

            self.prediction_count += 1

            self.context_buffer.clear()
            print(f"\nBuffer cleared. Collecting next {CONTEXT_BUFFER_SIZE} timesteps...")
            print("=" * 60 + "\n")

        except Exception as e:
            print(f"Error in predict: {e}")
            import traceback
            traceback.print_exc()

    # -------------------------------------------------------------- PUBLISHING
    def publish_prediction(self, prediction: np.ndarray):
        """
        ì˜ˆì¸¡ ê²°ê³¼ì™€ ì»¨í…ìŠ¤íŠ¸ ì‹œí€€ìŠ¤ë¥¼ ZeroMQë¡œ ì†¡ì‹  (FR4, FR5).
        """
        timestamp = time.time()
        context_window = np.array(self.context_buffer, dtype=np.float32).tolist()

        payload = {
            "timestamp": timestamp,
            "zones": ZONES,
            "prediction": prediction.astype(float).tolist(),
            "context_window": context_window,
            "sequence_length": CONTEXT_BUFFER_SIZE,
            "prediction_index": self.prediction_count,
        }

        try:
            self.zmq_pub_federated.send_pyobj(
                {
                    "source": "gru_predictor",
                    "target": "federated_learning",
                    "payload": payload,
                }
            )
            self.zmq_pub_policy.send_pyobj(
                {
                    "source": "gru_predictor",
                    "target": "policy_engine",
                    "payload": payload,
                }
            )
            print("ğŸ“¡ Published prediction to FR4(FedPer) and FR5(Policy) ZeroMQ buses.")
        except Exception as exc:
            print(f"Error while publishing prediction over ZeroMQ: {exc}")

    # -------------------------------------------------------------------- LOOP
    def run(self):
        """
        ì˜ˆì¸¡ê¸° ë©”ì¸ ë£¨í”„ (í´ë§).
        """
        print("GRU Predictor started!")
        print(f"  - Waiting for {CONTEXT_BUFFER_SIZE} timesteps of synced sensor data...")
        print("  - Sensors expected: visual, audio, pose, spatial, time")
        print("  - Press Ctrl+C to quit\n")

        try:
            while True:
                self.receive_messages()
        except KeyboardInterrupt:
            print("\nKeyboard interrupt, stopping...")
        finally:
            self.cleanup()

    # ----------------------------------------------------------------- CLEANUP
    def cleanup(self):
        """ì‚¬ìš©í•œ ë¦¬ì†ŒìŠ¤ë¥¼ ì •ë¦¬í•©ë‹ˆë‹¤."""
        print("\nCleaning up GRU Predictor...")
        self.zmq_socket.close()
        self.zmq_pub_federated.close()
        self.zmq_pub_policy.close()
        self.zmq_context.term()
        print("GRU Predictor stopped!")
        print("\nStatistics:")
        print(f"  - Total timesteps collected: {self.timestep_count}")
        print(f"  - Total predictions made: {self.prediction_count}")
        print(f"  - Sync failures (dropped): {self.time_sync.dropped}")


if __name__ == "__main__":
    predictor = GRUPredictor()
    predictor.run()
