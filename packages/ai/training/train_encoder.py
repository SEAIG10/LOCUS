"""
AttentionContextEncoder í•™ìŠµ ìŠ¤í¬ë¦½íŠ¸ (Updated for Realistic Dataset)

í˜„ì‹¤ì ì¸ ì¼ìƒ ë£¨í‹´ ë°ì´í„°ì…‹ìœ¼ë¡œ AttentionEncoderë¥¼ í•™ìŠµì‹œí‚µë‹ˆë‹¤.
í•™ìŠµ ëª©í‘œ: ë‹¤ì¤‘ ëª¨ë‹¬ ì„¼ì„œ íŠ¹ì§• (visual, audio, pose, spatial, time) â†’ 160ì°¨ì› ì»¨í…ìŠ¤íŠ¸ ë²¡í„° ë³€í™˜
ì†ì‹¤: ì»¨í…ìŠ¤íŠ¸ ë²¡í„°ê°€ 4ê°œ êµ¬ì—­ì˜ ì˜¤ì—¼ë„ë¥¼ ì˜ˆì¸¡í•  ìˆ˜ ìˆë„ë¡ í•™ìŠµ (regression)
"""

import os
import sys
import numpy as np
import tensorflow as tf
from tensorflow.keras import callbacks
import matplotlib.pyplot as plt

# í”„ë¡œì íŠ¸ ê²½ë¡œ ì¶”ê°€
sys.path.insert(0, os.path.join(os.path.dirname(__file__), '..'))

from core.context_fusion.attention_context_encoder import create_attention_encoder
from training.config import SENSOR_DIMS, ENCODER_CONFIG, ENCODER_TRAINING, PATHS


class EncoderTrainer:
    """AttentionContextEncoder í•™ìŠµ í´ë˜ìŠ¤"""

    def __init__(self):
        """í•™ìŠµê¸°ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.encoder = None
        self.prediction_head = None
        self.full_model = None

    def build_model(self, num_zones=4):
        """
        í•™ìŠµì„ ìœ„í•œ ëª¨ë¸ì„ êµ¬ì¶•í•©ë‹ˆë‹¤.

        AttentionEncoder + ì˜ˆì¸¡ í—¤ë“œ ì¡°í•©:
        - AttentionEncoder: íŠ¹ì§• ìœµí•© (í•™ìŠµ ëŒ€ìƒ, Base Layer for FedPer)
        - ì˜ˆì¸¡ í—¤ë“œ: ì„ì‹œ regression ë ˆì´ì–´ (ì¸ì½”ë” í•™ìŠµìš©, ë‚˜ì¤‘ì— ë²„ë¦¼)
        """
        print("\n" + "=" * 70)
        print("AttentionContextEncoder ëª¨ë¸ êµ¬ì¶•")
        print("=" * 70)

        # AttentionEncoder ìƒì„±
        self.encoder = create_attention_encoder(
            visual_dim=SENSOR_DIMS['visual'],
            audio_dim=SENSOR_DIMS['audio'],
            pose_dim=SENSOR_DIMS['pose'],
            spatial_dim=SENSOR_DIMS['spatial'],
            time_dim=SENSOR_DIMS['time'],
            context_dim=ENCODER_CONFIG['context_dim']
        )

        print("\n[AttentionContextEncoder]")
        self.encoder.summary()

        # ì˜ˆì¸¡ í—¤ë“œ ìƒì„± (í•™ìŠµìš©, regression)
        # ì´ ë ˆì´ì–´ëŠ” ì¸ì½”ë”ê°€ ì˜ë¯¸ ìˆëŠ” íŠ¹ì§•ì„ í•™ìŠµí•˜ë„ë¡ ë•ìŠµë‹ˆë‹¤.
        context_input = tf.keras.Input(
            shape=(ENCODER_CONFIG['context_dim'],),
            name='context_vector'
        )
        x = tf.keras.layers.Dense(64, activation='relu', name='pred_hidden')(context_input)
        x = tf.keras.layers.Dropout(0.3, name='pred_dropout')(x)
        output = tf.keras.layers.Dense(num_zones, activation='sigmoid', name='pred_output')(x)

        self.prediction_head = tf.keras.Model(
            inputs=context_input,
            outputs=output,
            name='prediction_head'
        )

        print("\n[ì˜ˆì¸¡ í—¤ë“œ (í•™ìŠµìš©, Regression)]")
        self.prediction_head.summary()

        # ì „ì²´ ëª¨ë¸: Encoder + ì˜ˆì¸¡ í—¤ë“œ
        # ì…ë ¥: ë‹¤ì¤‘ ëª¨ë‹¬ íŠ¹ì§•
        # ì¶œë ¥: 4ê°œ êµ¬ì—­ì˜ ì˜¤ì—¼ë„ (0~1)
        inputs = {
            'visual': tf.keras.Input(shape=(SENSOR_DIMS['visual'],), name='visual'),
            'audio': tf.keras.Input(shape=(SENSOR_DIMS['audio'],), name='audio'),
            'pose': tf.keras.Input(shape=(SENSOR_DIMS['pose'],), name='pose'),
            'spatial': tf.keras.Input(shape=(SENSOR_DIMS['spatial'],), name='spatial'),
            'time': tf.keras.Input(shape=(SENSOR_DIMS['time'],), name='time'),
        }

        context = self.encoder(inputs)
        predictions = self.prediction_head(context)

        self.full_model = tf.keras.Model(
            inputs=inputs,
            outputs=predictions,
            name='encoder_training_model'
        )

        print("\n[ì „ì²´ í•™ìŠµ ëª¨ë¸]")
        self.full_model.summary()

        print("\n" + "=" * 70 + "\n")

    def compile_model(self):
        """ëª¨ë¸ì„ ì»´íŒŒì¼í•©ë‹ˆë‹¤ (Regression)."""
        self.full_model.compile(
            optimizer=tf.keras.optimizers.Adam(
                learning_rate=ENCODER_TRAINING['learning_rate']
            ),
            loss='mse',  # Regression: Mean Squared Error
            metrics=['mae', 'mse']
        )
        print("ëª¨ë¸ ì»´íŒŒì¼ ì™„ë£Œ (Regression MSE)\n")

    def train(
        self,
        features_train: dict,
        labels_train: np.ndarray,
        features_val: dict,
        labels_val: np.ndarray
    ):
        """
        ëª¨ë¸ì„ í•™ìŠµì‹œí‚µë‹ˆë‹¤.

        Args:
            features_train: í›ˆë ¨ íŠ¹ì§• ë”•ì…”ë„ˆë¦¬
                - 'time': (N, 10)
                - 'spatial': (N, 4)
                - 'visual': (N, 14)
                - 'audio': (N, 17)
                - 'pose': (N, 51)
            labels_train: í›ˆë ¨ ë ˆì´ë¸” (N, 4)
            features_val: ê²€ì¦ íŠ¹ì§• (ë™ì¼ êµ¬ì¡°)
            labels_val: ê²€ì¦ ë ˆì´ë¸” (N_val, 4)

        Returns:
            history: í•™ìŠµ ê¸°ë¡
        """
        print("\n" + "=" * 70)
        print("AttentionContextEncoder í•™ìŠµ ì‹œì‘")
        print("=" * 70 + "\n")

        print(f"í›ˆë ¨ ìƒ˜í”Œ: {labels_train.shape[0]:,}ê°œ")
        print(f"ê²€ì¦ ìƒ˜í”Œ: {labels_val.shape[0]:,}ê°œ")
        print(f"ì…ë ¥ features:")
        for key, value in features_train.items():
            print(f"  {key:10s}: {value.shape}")
        print(f"ì¶œë ¥ labels: {labels_train.shape}\n")

        # ì½œë°± ì„¤ì •
        print("[ì½œë°± ì„¤ì •]")
        callback_list = [
            callbacks.EarlyStopping(
                monitor='val_loss',
                patience=ENCODER_TRAINING['early_stopping_patience'],
                restore_best_weights=True,
                verbose=1
            ),
            callbacks.ReduceLROnPlateau(
                monitor='val_loss',
                factor=0.5,
                patience=ENCODER_TRAINING['reduce_lr_patience'],
                min_lr=ENCODER_TRAINING['min_lr'],
                verbose=1
            ),
            callbacks.ModelCheckpoint(
                filepath=PATHS['encoder_model'],
                monitor='val_loss',
                save_best_only=True,
                verbose=1
            )
        ]

        # í•™ìŠµ
        print("\n[í•™ìŠµ ì§„í–‰ ì¤‘...]\n")
        history = self.full_model.fit(
            features_train, labels_train,
            validation_data=(features_val, labels_val),
            epochs=ENCODER_TRAINING['epochs'],
            batch_size=ENCODER_TRAINING['batch_size'],
            callbacks=callback_list,
            verbose=1
        )

        print("\n" + "=" * 70)
        print("í•™ìŠµ ì™„ë£Œ!")
        print("=" * 70 + "\n")

        return history

    def save_encoder(self, save_path: str = None):
        """
        í•™ìŠµëœ AttentionEncoderë§Œ ì €ì¥í•©ë‹ˆë‹¤.
        (ì˜ˆì¸¡ í—¤ë“œëŠ” ë²„ë¦½ë‹ˆë‹¤ - GRUê°€ ìƒˆë¡œìš´ Headê°€ ë  ê²ƒ)

        Args:
            save_path: ì €ì¥ ê²½ë¡œ (ê¸°ë³¸ê°’: config)
        """
        if save_path is None:
            save_path = PATHS['encoder_model']

        self.encoder.save(save_path)
        print(f"âœ… AttentionEncoderê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {save_path}")

        # ëª¨ë¸ í¬ê¸° ì •ë³´
        file_size_mb = os.path.getsize(save_path) / (1024 * 1024)
        print(f"  íŒŒì¼ í¬ê¸°: {file_size_mb:.2f} MB")

    def evaluate(self, features_val: dict, labels_val: np.ndarray, zone_names: list):
        """
        ëª¨ë¸ì„ í‰ê°€í•©ë‹ˆë‹¤.

        Args:
            features_val: ê²€ì¦ íŠ¹ì§•
            labels_val: ê²€ì¦ ë ˆì´ë¸”
            zone_names: êµ¬ì—­ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
        """
        print("\n" + "=" * 70)
        print("AttentionEncoder í‰ê°€")
        print("=" * 70 + "\n")

        # ì˜ˆì¸¡
        y_pred = self.full_model.predict(features_val, verbose=0)

        # êµ¬ì—­ë³„ í‰ê°€
        print("êµ¬ì—­ë³„ ì„±ëŠ¥ (Regression):")
        print("-" * 70)
        for i, zone in enumerate(zone_names):
            mae = np.mean(np.abs(labels_val[:, i] - y_pred[:, i]))
            mse = np.mean((labels_val[:, i] - y_pred[:, i]) ** 2)
            rmse = np.sqrt(mse)

            print(f"{zone:15s}: MAE={mae:.4f}, MSE={mse:.4f}, RMSE={rmse:.4f}")

        # ì „ì²´ í‰ê°€
        overall_mae = np.mean(np.abs(labels_val - y_pred))
        overall_rmse = np.sqrt(np.mean((labels_val - y_pred) ** 2))

        print("-" * 70)
        print(f"{'Overall':15s}: MAE={overall_mae:.4f}, RMSE={overall_rmse:.4f}")
        print("=" * 70 + "\n")


def plot_training_history(history, save_path: str = None):
    """
    í•™ìŠµ ê¸°ë¡ì„ ì‹œê°í™”í•©ë‹ˆë‹¤.

    Args:
        history: Keras í•™ìŠµ ê¸°ë¡
        save_path: ì €ì¥ ê²½ë¡œ
    """
    if save_path is None:
        save_path = PATHS['encoder_history']

    fig, axes = plt.subplots(1, 2, figsize=(12, 5))

    # ì†ì‹¤
    axes[0].plot(history.history['loss'], label='Train Loss (MSE)')
    axes[0].plot(history.history['val_loss'], label='Val Loss (MSE)')
    axes[0].set_title('Encoder Training Loss')
    axes[0].set_xlabel('Epoch')
    axes[0].set_ylabel('MSE')
    axes[0].legend()
    axes[0].grid(True)

    # MAE
    if 'mae' in history.history:
        axes[1].plot(history.history['mae'], label='Train MAE')
        axes[1].plot(history.history['val_mae'], label='Val MAE')
        axes[1].set_title('Encoder Training MAE')
        axes[1].set_xlabel('Epoch')
        axes[1].set_ylabel('MAE')
        axes[1].legend()
        axes[1].grid(True)

    plt.tight_layout()
    plt.savefig(save_path, dpi=150, bbox_inches='tight')
    print(f"ğŸ“Š í•™ìŠµ ê¸°ë¡ ê·¸ë˜í”„ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {save_path}")


def save_training_metrics(history, save_path: str = None):
    """
    í•™ìŠµ ì§€í‘œë¥¼ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        history: Keras í•™ìŠµ ê¸°ë¡
        save_path: ì €ì¥ ê²½ë¡œ
    """
    if save_path is None:
        save_path = os.path.join(PATHS['results_dir'], 'encoder_metrics.txt')

    with open(save_path, 'w') as f:
        f.write("=" * 70 + "\n")
        f.write("AttentionEncoder í•™ìŠµ ê²°ê³¼\n")
        f.write("=" * 70 + "\n\n")

        # ìµœì¢… ì—í¬í¬ ì •ë³´
        final_epoch = len(history.history['loss'])
        f.write(f"ì´ í•™ìŠµ ì—í¬í¬: {final_epoch}\n\n")

        # ìµœê³  ì„±ëŠ¥
        f.write("ìµœê³  ì„±ëŠ¥ (Validation):\n")
        f.write("-" * 70 + "\n")
        best_epoch = np.argmin(history.history['val_loss']) + 1
        best_val_loss = min(history.history['val_loss'])
        best_val_mae = history.history['val_mae'][best_epoch - 1] if 'val_mae' in history.history else None

        f.write(f"  Best Epoch: {best_epoch}\n")
        f.write(f"  Val Loss (MSE): {best_val_loss:.6f}\n")
        if best_val_mae:
            f.write(f"  Val MAE: {best_val_mae:.6f}\n")
        f.write("\n")

        # ìµœì¢… ì„±ëŠ¥
        f.write("ìµœì¢… ì„±ëŠ¥:\n")
        f.write("-" * 70 + "\n")
        f.write(f"  Train Loss: {history.history['loss'][-1]:.6f}\n")
        f.write(f"  Val Loss: {history.history['val_loss'][-1]:.6f}\n")
        if 'mae' in history.history:
            f.write(f"  Train MAE: {history.history['mae'][-1]:.6f}\n")
            f.write(f"  Val MAE: {history.history['val_mae'][-1]:.6f}\n")
        f.write("\n")

        # ì—í¬í¬ë³„ ìƒì„¸ ê¸°ë¡
        f.write("ì—í¬í¬ë³„ ìƒì„¸ ê¸°ë¡:\n")
        f.write("-" * 70 + "\n")
        f.write(f"{'Epoch':>6} {'Train Loss':>12} {'Val Loss':>12} {'Train MAE':>12} {'Val MAE':>12}\n")
        f.write("-" * 70 + "\n")

        for i in range(final_epoch):
            train_loss = history.history['loss'][i]
            val_loss = history.history['val_loss'][i]
            train_mae = history.history['mae'][i] if 'mae' in history.history else 0
            val_mae = history.history['val_mae'][i] if 'val_mae' in history.history else 0

            f.write(f"{i+1:6d} {train_loss:12.6f} {val_loss:12.6f} {train_mae:12.6f} {val_mae:12.6f}\n")

        f.write("\n" + "=" * 70 + "\n")

    print(f"ğŸ“ í•™ìŠµ ì§€í‘œê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {save_path}")


def main():
    """ë©”ì¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸"""
    print("\n" + "=" * 70)
    print("AttentionContextEncoder í•™ìŠµ íŒŒì´í”„ë¼ì¸ (Realistic Dataset)")
    print("=" * 70)

    # ===== ë‹¨ê³„ 1: ë°ì´í„° ë¡œë“œ =====
    print("\n[ë‹¨ê³„ 1] ë°ì´í„° ë¡œë“œ ì¤‘...")

    data_path = os.path.join(PATHS['data_dir'], 'realistic_training_dataset.npz')

    if not os.path.exists(data_path):
        print(f"\nâš ï¸  ì˜¤ë¥˜: í•™ìŠµ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {data_path}")
        print("ë¨¼ì € ë‹¤ìŒ ëª…ë ¹ì„ ì‹¤í–‰í•˜ì—¬ ë°ì´í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”:")
        print("  python training/prepare_data.py")
        return

    data = np.load(data_path, allow_pickle=True)

    # Features ë¡œë“œ
    features_all = {
        'time': data['time'],
        'spatial': data['spatial'],
        'visual': data['visual'],
        'audio': data['audio'],
        'pose': data['pose']
    }
    labels_all = data['y']
    metadata = data['metadata'].item()

    print(f"  âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ")
    print(f"  Total timesteps: {len(labels_all):,}")
    print(f"  Zones: {metadata['zones']}")

    # ===== ë‹¨ê³„ 2: Train/Val Split =====
    print("\n[ë‹¨ê³„ 2] Train/Val Split...")

    train_split = 0.8
    n_train = int(len(labels_all) * train_split)

    features_train = {key: value[:n_train] for key, value in features_all.items()}
    features_val = {key: value[n_train:] for key, value in features_all.items()}
    labels_train = labels_all[:n_train]
    labels_val = labels_all[n_train:]

    print(f"  í›ˆë ¨ ë°ì´í„°: {len(labels_train):,}ê°œ")
    print(f"  ê²€ì¦ ë°ì´í„°: {len(labels_val):,}ê°œ")

    # ===== ë‹¨ê³„ 3: Encoder Trainer ì´ˆê¸°í™” =====
    print("\n[ë‹¨ê³„ 3] Encoder Trainer ì´ˆê¸°í™” ì¤‘...")
    trainer = EncoderTrainer()

    # ===== ë‹¨ê³„ 4: ëª¨ë¸ êµ¬ì¶• =====
    print("\n[ë‹¨ê³„ 4] ëª¨ë¸ êµ¬ì¶• ì¤‘...")
    trainer.build_model(num_zones=4)

    # ===== ë‹¨ê³„ 5: ëª¨ë¸ ì»´íŒŒì¼ =====
    print("\n[ë‹¨ê³„ 5] ëª¨ë¸ ì»´íŒŒì¼ ì¤‘...")
    trainer.compile_model()

    # ===== ë‹¨ê³„ 6: í•™ìŠµ =====
    print("\n[ë‹¨ê³„ 6] í•™ìŠµ ì‹œì‘...")
    history = trainer.train(
        features_train, labels_train,
        features_val, labels_val
    )

    # ===== ë‹¨ê³„ 7: í‰ê°€ =====
    print("\n[ë‹¨ê³„ 7] ëª¨ë¸ í‰ê°€...")
    trainer.evaluate(features_val, labels_val, zone_names=metadata['zones'])

    # ===== ë‹¨ê³„ 8: Encoder ì €ì¥ =====
    print("\n[ë‹¨ê³„ 8] AttentionEncoder ì €ì¥...")
    trainer.save_encoder()

    # ===== ë‹¨ê³„ 9: í•™ìŠµ ê¸°ë¡ ì‹œê°í™” ë° ì €ì¥ =====
    print("\n[ë‹¨ê³„ 9] í•™ìŠµ ê¸°ë¡ ì‹œê°í™” ë° ì €ì¥...")
    plot_training_history(history)
    save_training_metrics(history)

    print("\n" + "=" * 70)
    print("âœ… AttentionEncoder í•™ìŠµ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
    print("=" * 70)
    print("\nì €ì¥ëœ íŒŒì¼:")
    print(f"  ğŸ“ {PATHS['encoder_model']} (í•™ìŠµëœ AttentionEncoder - Base Layer)")
    print(f"  ğŸ“Š {PATHS['encoder_history']} (í•™ìŠµ ê·¸ë˜í”„)")
    print(f"  ğŸ“ {os.path.join(PATHS['results_dir'], 'encoder_metrics.txt')} (ì„±ëŠ¥ ì§€í‘œ)")
    print("\në‹¤ìŒ ë‹¨ê³„:")
    print("  python training/train_gru.py  # GRU Head Layer í•™ìŠµ")


if __name__ == "__main__":
    main()
